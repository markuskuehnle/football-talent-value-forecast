{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a13822",
   "metadata": {},
   "source": [
    "# 00 Data Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debf442",
   "metadata": {},
   "source": [
    "This notebook scrapes structured player statistics for Valencia CF from [FBref](https://fbref.com) across three seasons (2022–2025). It includes:\n",
    "\n",
    "* **Seasonal data scraping:** Extracts 7 core stat tables (e.g. passing, defense, possession) for each season using `pandas.read_html` from public FBref squad pages\n",
    "* **Automated filename mapping:** Dynamically names and saves each table as a CSV in `data/raw/` using season and table type\n",
    "* **Rate limit protection:** Implements a request counter and 15-minute cooldown after 10 requests to avoid getting blocked by FBref\n",
    "* **Reproducible storage:** Skips already-downloaded files to prevent unnecessary re-fetches and ensure consistent local copies\n",
    "\n",
    "> Output of this notebook is a version-controlled local dump of raw FBref tables for further inspection, cleaning, and analysis. Scraper code is commented out after use to avoid accidental API overload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85eb92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import ssl\n",
    "import time\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.parse\n",
    "import io\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Import our scraper module using relative path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.scrapers.fbref_scraper import scrape_fbref_squad, FBrefScraper\n",
    "from src.scrapers.transfermarkt_scraper import scrape_transfermarkt_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1435d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c00665",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fccd411",
   "metadata": {},
   "source": [
    "## FBref Data Scraper\n",
    "- Saved to CSV files in notebooks/data/raw to avoid hitting HTTP request limit\n",
    "- Will comment the code to not run it (unless needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a090093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Current season 2024-2025\n",
    "# df_player_stats_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_standard_12\"})[0]\n",
    "# df_player_shooting_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_shooting_12\"})[0]\n",
    "# df_player_passing_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_passing_12\"})[0]\n",
    "# df_player_passing_types_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_passing_types_12\"})[0]\n",
    "# df_player_gca_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_gca_12\"})[0]\n",
    "# df_player_defense_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_defense_12\"})[0]\n",
    "# df_player_possession_2425 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/Valencia-Stats', attrs={\"id\": \"stats_possession_12\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3274094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Season 2023-2024\n",
    "# df_player_stats_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_standard_12\"})[0]\n",
    "# df_player_shooting_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_shooting_12\"})[0]\n",
    "# df_player_passing_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_passing_12\"})[0]\n",
    "# df_player_passing_types_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_passing_types_12\"})[0]\n",
    "# df_player_gca_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_gca_12\"})[0]\n",
    "# df_player_defense_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_defense_12\"})[0]\n",
    "# df_player_possession_2324 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats', attrs={\"id\": \"stats_possession_12\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b0d8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Season 2022-2023\n",
    "# df_player_stats_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_standard_12\"})[0]\n",
    "# df_player_shooting_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_shooting_12\"})[0]\n",
    "# df_player_passing_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_passing_12\"})[0]\n",
    "# df_player_passing_types_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_passing_types_12\"})[0]\n",
    "# df_player_gca_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_gca_12\"})[0]\n",
    "# df_player_defense_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_defense_12\"})[0]\n",
    "# df_player_possession_2223 = pd.read_html('https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats', attrs={\"id\": \"stats_possession_12\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df5cbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Save all dataframes to CSV files for future use #####\n",
    "\n",
    "# # 1 Folder →  data/raw   (create if it doesn't exist)\n",
    "\n",
    "# RAW_DIR = Path(\"..\", \"data\", \"raw\")\n",
    "# RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # 2 Find every variable in the notebook whose name starts with df_\n",
    "# frames = {\n",
    "#     name: obj\n",
    "#     for name, obj in globals().items()\n",
    "#     if name.startswith(\"df_\") and isinstance(obj, pd.DataFrame)\n",
    "# }\n",
    "\n",
    "# # 3  Save each DataFrame to CSV\n",
    "# for name, df in frames.items():\n",
    "#     filepath = RAW_DIR / f\"{name}.csv\"\n",
    "#     df.to_csv(filepath, index=False)\n",
    "#     print(f\"{filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "667bde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_URLS = {\n",
    "#     \"2425\": \"https://fbref.com/en/squads/dcc91a7b/Valencia-Stats\",\n",
    "#     \"2324\": \"https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats\",\n",
    "#     \"2223\": \"https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats\",\n",
    "# }\n",
    "\n",
    "# TABLE_IDS = [\n",
    "#     \"stats_standard_12\",\n",
    "#     \"stats_shooting_12\",\n",
    "#     \"stats_passing_12\",\n",
    "#     \"stats_passing_types_12\",\n",
    "#     \"stats_gca_12\",\n",
    "#     \"stats_defense_12\",\n",
    "#     \"stats_possession_12\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45a20f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only 10 requests per 15 minutes\n",
    "# MAX_REQUESTS = 10\n",
    "# COOLDOWN_SECONDS = 15 * 60  # 15 minutes\n",
    "\n",
    "# request_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0f57b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_suffix(table_id: str, suffix=\"_12\") -> str:\n",
    "#     return table_id[:-len(suffix)] if table_id.endswith(suffix) else table_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bdf80",
   "metadata": {},
   "source": [
    "We added a request counter and cooldown timer to the scraper to avoid triggering FBref’s rate limits and getting blocked after multiple table fetches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f47fb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for season, url in BASE_URLS.items():\n",
    "#     for table_id in TABLE_IDS:\n",
    "#         table_base = strip_suffix(table_id)\n",
    "#         if table_base == \"stats_standard\":\n",
    "#             fname = f\"df_player_stats_{season}.csv\"\n",
    "#         else:\n",
    "#             fname = f\"df_player_{table_base.replace('stats_', '')}_{season}.csv\"\n",
    "#         fpath = RAW_DIR / fname\n",
    "\n",
    "#         if fpath.exists():\n",
    "#             print(f\"Skipping existing file: {fname}\")\n",
    "#             continue\n",
    "\n",
    "#         if request_counter >= MAX_REQUESTS:\n",
    "#             print(f\"Request cap hit. Cooling down for {COOLDOWN_SECONDS // 60} minutes...\")\n",
    "#             time.sleep(COOLDOWN_SECONDS)\n",
    "#             request_counter = 0\n",
    "\n",
    "#         try:\n",
    "#             print(f\"Fetching: {season} | {table_id}\")\n",
    "#             df = pd.read_html(url, attrs={\"id\": table_id})[0]\n",
    "#             df.to_csv(fpath, index=False)\n",
    "#             print(f\"Saved {fpath.name}\")\n",
    "#             request_counter += 1\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to fetch {table_id} for {season}: {e}\")\n",
    "\n",
    "#         time.sleep(random.uniform(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37988b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"Valencia CF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d5a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valencia CF URLs for different seasons\n",
    "valencia_urls = {\n",
    "    \"2425\": \"https://fbref.com/en/squads/dcc91a7b/Valencia-Stats\",\n",
    "    \"2324\": \"https://fbref.com/en/squads/dcc91a7b/2023-2024/Valencia-Stats\", \n",
    "    \"2223\": \"https://fbref.com/en/squads/dcc91a7b/2022-2023/Valencia-Stats\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR_FBREF = Path(\"..\", \"data\", \"raw\", team_name, \"fbref\")\n",
    "RAW_DIR_FBREF.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scraper instance with custom settings\n",
    "scraper = FBrefScraper(\n",
    "    output_dir=RAW_DIR_FBREF,\n",
    "    max_requests=10,\n",
    "    cooldown_seconds=15 * 60,\n",
    "    delay_range=(5, 10),\n",
    "    current_season=\"2425\"\n",
    ")\n",
    "\n",
    "# Scrape all seasons\n",
    "for season, url in valencia_urls.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping Valencia CF season {season}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = scraper.scrape_squad_stats(url, force_overwrite=False)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"Successfully scraped {len(result)} tables for season {season}\")\n",
    "    else:\n",
    "        print(f\"No data scraped for season {season}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f1542",
   "metadata": {},
   "source": [
    "# Scrape Market Value Historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f6e97",
   "metadata": {},
   "source": [
    "- Encountered difficulties scraping market data from trasnfermarkt\n",
    "- Used a service called Apify to scrape (it's paid but has a good free tier)\n",
    "- Testing it below by running scraper in browser and saving file\n",
    "- Still needs adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd671073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ── 1) read the file (local) ──────────────────────────────────────────────\n",
    "# json_path = pathlib.Path(\n",
    "#     \"..\", \"data\", \"raw\", \"dataset_transfermarkt_2025-06-15_15-34-31-954.json\"\n",
    "# )                     # <— adjust if you stored it elsewhere\n",
    "\n",
    "# with json_path.open(encoding=\"utf-8\") as f:\n",
    "#     data = json.load(f)          # top level is a list with a single club dict\n",
    "\n",
    "# # ── 2) flatten the “players” list into a table ────────────────────────────\n",
    "# club_record = data[0]            # only one element\n",
    "# players_raw = club_record[\"players\"]\n",
    "\n",
    "# df_players = pd.json_normalize(players_raw)  # one row per player\n",
    "# df_players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e0b5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44ee8f",
   "metadata": {},
   "source": [
    "## Transfermarkt Data Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c70e19",
   "metadata": {},
   "source": [
    "- Below is the Apify scraper code to extract valencia market value of players for season 2022,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os, json, requests, pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv          # pip install python-dotenv\n",
    "\n",
    "# ── environment ───────────────────────────────────────────────────────────────\n",
    "load_dotenv()\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_TOKEN\")          \n",
    "if not APIFY_TOKEN:\n",
    "    raise RuntimeError(\"Set APIFY_TOKEN first – never hard-code it in notebooks!\")\n",
    "\n",
    "ACTOR  = \"curious_coder~transfermarkt\"\n",
    "ENDPT  = (f\"https://api.apify.com/v2/acts/{ACTOR}\"\n",
    "          \"/run-sync-get-dataset-items?token=\" + APIFY_TOKEN +\n",
    "          \"&clean=true&format=json\")\n",
    "\n",
    "BASE_URL = (\"https://www.transfermarkt.co.uk/valencia-cf/kader/verein/1049/\"\n",
    "            \"plus/0/galerie/0?saison_id={year}\")\n",
    "\n",
    "def fetch_squad(year: int) -> pd.DataFrame:\n",
    "    #Run the Transfermarkt actor for one Valencia squad year → DataFrame.\n",
    "    payload = {\n",
    "        \"startUrls\": [ { \"url\": BASE_URL.format(year=year) } ],  # <- corrected\n",
    "        \"proxyConfiguration\": { \"useApifyProxy\": True },         # free pool only\n",
    "        \"maxCrawlingDepth\": 0\n",
    "    }\n",
    "\n",
    "    r = requests.post(ENDPT, json=payload, timeout=180)\n",
    "    if r.status_code >= 400:\n",
    "        raise RuntimeError(f\"{year}: HTTP {r.status_code}\\n{r.text}\")\n",
    "\n",
    "    rows = r.json()\n",
    "    if rows and \"error.type\" in rows[0]:\n",
    "        msg = rows[0].get(\"error.message\", \"no message\")\n",
    "        raise RuntimeError(f\"{year}: actor error – {msg}\")\n",
    "\n",
    "    # actor returns one club record → extract player list\n",
    "    club_record    = rows[0]\n",
    "    players_raw    = club_record[\"players\"]\n",
    "    df_players     = pd.json_normalize(players_raw)\n",
    "    df_players[\"Season\"] = year\n",
    "    return df_players\n",
    "\n",
    "\n",
    "# ── fetch three seasons & inspect ────────────────────────────────────────────\n",
    "seasons   = [2022, 2023, 2024]\n",
    "valencia_player_value  = pd.concat([fetch_squad(y) for y in seasons], ignore_index=True)\n",
    "\n",
    "valencia_player_value.to_csv(RAW_DIR / \"valencia_market_value_22_25.csv\", index=False)\n",
    "\n",
    "# valencia_player_value = pd.read_csv(RAW_DIR / \"valencia_market_value_22_25.csv\")\n",
    "\n",
    "# valencia_player_value.head()\n",
    "\n",
    "# javi_guerra_rows = valencia_player_value[valencia_player_value['Player'].astype(str).str.contains('Javi Guerra')]\n",
    "# javi_guerra_rows\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a48500",
   "metadata": {},
   "source": [
    "**Expected Format**\n",
    "\n",
    "| # | Player | Age | Current club | Market value | Nat. | Season | Contract |\n",
    "|---|--------|-----|--------------|--------------|------|--------|----------|\n",
    "| 36.0 | ['Javi Guerra', 'Central Midfield'] | 20 | Valencia CF | €2.00m | Spain | 2022 | NaN |\n",
    "| 8.0 | ['Javi Guerra', 'Central Midfield'] | 21 | Valencia CF | €20.00m | Spain | 2023 | NaN |\n",
    "| 8.0 | ['Javi Guerra', 'Central Midfield'] | 22 | NaN | €25.00m | Spain | 2024 | Jun 30, 2027 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6aa32",
   "metadata": {},
   "source": [
    "- We can see the market value of Javi Guerra.\n",
    "- Interesting features are: Position, Market Value, Contract length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbe130",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b6708",
   "metadata": {},
   "source": [
    "# Transfermarkt Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c57e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"Valencia CF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393db11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR_TRANSFERMARKET = Path(\"..\", \"data\", \"raw\", team_name, \"transfermarkt\")\n",
    "RAW_DIR_TRANSFERMARKET.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6403f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_season = 2020\n",
    "max_season = 2024\n",
    "\n",
    "valencia_team_data = scrape_transfermarkt_team(\n",
    "    team_name=team_name,\n",
    "    min_season=min_season,\n",
    "    max_season=max_season,\n",
    "    output_dir=RAW_DIR_TRANSFERMARKET,\n",
    "    output_filename=\"valencia_market_values_22_25.csv\",\n",
    "    drop_metadata_columns=True\n",
    ")\n",
    "\n",
    "valencia_team_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17729d2",
   "metadata": {},
   "source": [
    "NOTE: This is our raw data, which we will save before cleaning it in the next pipeline step and merging it with the other data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7a134",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42faf5d",
   "metadata": {},
   "source": [
    "# Scrape multiple teams (transfermarkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d406e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape Real Madrid CF players from season 2020 to 2024\n",
      "------------------------------------------------------------\n",
      "Scraping Real Madrid CF season 2020...\n",
      "Successfully scraped 37 players for Real Madrid CF season 2020\n",
      "Waiting 1.7 seconds before next request...\n",
      "Scraping Real Madrid CF season 2021...\n",
      "Successfully scraped 36 players for Real Madrid CF season 2021\n",
      "Waiting 2.2 seconds before next request...\n",
      "Scraping Real Madrid CF season 2022...\n",
      "Successfully scraped 36 players for Real Madrid CF season 2022\n",
      "Waiting 2.3 seconds before next request...\n",
      "Scraping Real Madrid CF season 2023...\n",
      "Successfully scraped 38 players for Real Madrid CF season 2023\n",
      "Waiting 2.0 seconds before next request...\n",
      "Scraping Real Madrid CF season 2024...\n",
      "Successfully scraped 29 players for Real Madrid CF season 2024\n",
      "\n",
      "Scraped 176 player records\n",
      "Dropped metadata columns: ['Shirt Number', 'Photo URL', 'Profile URL']\n",
      "\n",
      "Data saved to ../data/raw/Real Madrid CF/transfermarkt/real_madrid_market_values_2020_2024.csv\n",
      "Total records: 176\n",
      "Scraped data for Real Madrid CF: 176 records\n",
      "Saved to: ../data/raw/Real Madrid CF/transfermarkt/real_madrid_market_values_2020_2024.csv\n",
      "--------------------------------------------------\n",
      "Starting to scrape FC Barcelona players from season 2020 to 2024\n",
      "------------------------------------------------------------\n",
      "Scraping FC Barcelona season 2020...\n",
      "Successfully scraped 32 players for FC Barcelona season 2020\n",
      "Waiting 2.7 seconds before next request...\n",
      "Scraping FC Barcelona season 2021...\n",
      "Successfully scraped 47 players for FC Barcelona season 2021\n",
      "Waiting 1.3 seconds before next request...\n",
      "Scraping FC Barcelona season 2022...\n",
      "Successfully scraped 41 players for FC Barcelona season 2022\n",
      "Waiting 2.6 seconds before next request...\n",
      "Scraping FC Barcelona season 2023...\n",
      "Successfully scraped 38 players for FC Barcelona season 2023\n",
      "Waiting 1.3 seconds before next request...\n",
      "Scraping FC Barcelona season 2024...\n",
      "Error scraping FC Barcelona season 2024: HTTP Error 503: Service Unavailable\n",
      "\n",
      "Scraped 158 player records\n",
      "Dropped metadata columns: ['Shirt Number', 'Photo URL', 'Profile URL']\n",
      "\n",
      "Data saved to ../data/raw/FC Barcelona/transfermarkt/barcelona_market_values_2020_2024.csv\n",
      "Total records: 158\n",
      "Scraped data for FC Barcelona: 158 records\n",
      "Saved to: ../data/raw/FC Barcelona/transfermarkt/barcelona_market_values_2020_2024.csv\n",
      "--------------------------------------------------\n",
      "Starting to scrape Atlético Madrid players from season 2020 to 2024\n",
      "------------------------------------------------------------\n",
      "Scraping Atlético Madrid season 2020...\n",
      "Successfully scraped 39 players for Atlético Madrid season 2020\n",
      "Waiting 1.3 seconds before next request...\n",
      "Scraping Atlético Madrid season 2021...\n",
      "Successfully scraped 43 players for Atlético Madrid season 2021\n",
      "Waiting 2.0 seconds before next request...\n",
      "Scraping Atlético Madrid season 2022...\n",
      "Error scraping Atlético Madrid season 2022: HTTP Error 503: Service Unavailable\n",
      "Waiting 2.2 seconds before next request...\n",
      "Scraping Atlético Madrid season 2023...\n",
      "Successfully scraped 42 players for Atlético Madrid season 2023\n",
      "Waiting 2.2 seconds before next request...\n",
      "Scraping Atlético Madrid season 2024...\n",
      "Error scraping Atlético Madrid season 2024: HTTP Error 503: Service Unavailable\n",
      "\n",
      "Scraped 124 player records\n",
      "Dropped metadata columns: ['Shirt Number', 'Photo URL', 'Profile URL']\n",
      "\n",
      "Data saved to ../data/raw/Atlético Madrid/transfermarkt/atlético_madrid_market_values_2020_2024.csv\n",
      "Total records: 124\n",
      "Scraped data for Atlético Madrid: 124 records\n",
      "Saved to: ../data/raw/Atlético Madrid/transfermarkt/atlético_madrid_market_values_2020_2024.csv\n",
      "--------------------------------------------------\n",
      "Starting to scrape Sevilla FC players from season 2020 to 2024\n",
      "------------------------------------------------------------\n",
      "Scraping Sevilla FC season 2020...\n",
      "Error scraping Sevilla FC season 2020: HTTP Error 503: Service Unavailable\n",
      "Waiting 1.7 seconds before next request...\n",
      "Scraping Sevilla FC season 2021...\n",
      "Error scraping Sevilla FC season 2021: HTTP Error 503: Service Unavailable\n",
      "Waiting 1.1 seconds before next request...\n",
      "Scraping Sevilla FC season 2022...\n",
      "Error scraping Sevilla FC season 2022: HTTP Error 503: Service Unavailable\n",
      "Waiting 1.9 seconds before next request...\n",
      "Scraping Sevilla FC season 2023...\n",
      "Error scraping Sevilla FC season 2023: HTTP Error 503: Service Unavailable\n",
      "Waiting 2.4 seconds before next request...\n",
      "Scraping Sevilla FC season 2024...\n",
      "Error scraping Sevilla FC season 2024: HTTP Error 503: Service Unavailable\n",
      "No data was scraped. Please check the team name and season range.\n",
      "Scraped data for Sevilla FC: 0 records\n",
      "Saved to: ../data/raw/Sevilla FC/transfermarkt/sevilla_market_values_2020_2024.csv\n",
      "--------------------------------------------------\n",
      "Starting to scrape Athletic Club players from season 2020 to 2024\n",
      "------------------------------------------------------------\n",
      "Scraping Athletic Club season 2020...\n",
      "Error scraping Athletic Club season 2020: HTTP Error 503: Service Unavailable\n",
      "Waiting 1.2 seconds before next request...\n",
      "Scraping Athletic Club season 2021...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m raw_dir_transfermarkt\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam_slug\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_market_values_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_season\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_season\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m team_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_transfermarkt_team\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteam_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_team_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_season\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_season\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_season\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_season\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_dir_transfermarkt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_metadata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraped data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_team_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(team_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_dir_transfermarkt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/projects/talent-value-forecast/notebooks/../src/scrapers/transfermarkt_scraper.py:373\u001b[0m, in \u001b[0;36mscrape_transfermarkt_team\u001b[0;34m(team_name, min_season, max_season, output_dir, output_filename, drop_metadata_columns)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function to scrape Transfermarkt team data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    DataFrame containing player data for all seasons\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m scraper \u001b[38;5;241m=\u001b[39m TransfermarktScraper(output_dir\u001b[38;5;241m=\u001b[39moutput_dir)\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_team\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteam_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteam_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_season\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_season\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_season\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_season\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_metadata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_metadata_columns\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/talent-value-forecast/notebooks/../src/scrapers/transfermarkt_scraper.py:324\u001b[0m, in \u001b[0;36mTransfermarktScraper.scrape_team\u001b[0;34m(self, team_name, min_season, max_season, output_filename, drop_metadata_columns)\u001b[0m\n\u001b[1;32m    322\u001b[0m team_slug \u001b[38;5;241m=\u001b[39m slug_id[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_slug\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    323\u001b[0m team_id \u001b[38;5;241m=\u001b[39m slug_id[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 324\u001b[0m team_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_team_multiple_seasons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_season\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_season\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_slug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteam_slug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteam_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m team_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScraped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(team_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m player records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/projects/talent-value-forecast/notebooks/../src/scrapers/transfermarkt_scraper.py:277\u001b[0m, in \u001b[0;36mTransfermarktScraper.scrape_team_multiple_seasons\u001b[0;34m(self, team_name, min_season, max_season, team_slug, team_id)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m season \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_season, max_season \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m season \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m     season_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_team_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_slug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteam_slug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteam_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m season_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    280\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(season_data)\n",
      "File \u001b[0;32m~/Documents/projects/talent-value-forecast/notebooks/../src/scrapers/transfermarkt_scraper.py:155\u001b[0m, in \u001b[0;36mTransfermarktScraper.scrape_team_season\u001b[0;34m(self, team_name, season, team_slug, team_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m ssl\u001b[38;5;241m.\u001b[39m_create_default_https_context \u001b[38;5;241m=\u001b[39m ssl\u001b[38;5;241m.\u001b[39m_create_unverified_context\n\u001b[1;32m    154\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m--> 155\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Parse with BeautifulSoup to get the exact table structure\u001b[39;00m\n\u001b[1;32m    158\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/urllib/request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.10.16-macos-aarch64-none/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TEAMS = [\n",
    "    \"Real Madrid CF\",\n",
    "    \"FC Barcelona\",\n",
    "    \"Atlético Madrid\",\n",
    "    \"Sevilla FC\", \n",
    "    \"Athletic Club\",\n",
    "    \"Villarreal CF\",\n",
    "    \"Real Sociedad\",\n",
    "    \"Real Betis\",\n",
    "    \"Valencia CF\",\n",
    "]\n",
    "\n",
    "min_season = 2020\n",
    "max_season = 2024\n",
    "\n",
    "for current_team_name in TEAMS:\n",
    "    team_slug = current_team_name.lower().replace(\" \", \"_\").replace(\"cf\", \"\").replace(\"fc\", \"\").strip(\"_\")\n",
    "    raw_dir_transfermarkt = Path(\"..\", \"data\", \"raw\", current_team_name, \"transfermarkt\")\n",
    "    raw_dir_transfermarkt.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_filename = f\"{team_slug}_market_values_{min_season}_{max_season}.csv\"\n",
    "    \n",
    "    team_data = scrape_transfermarkt_team(\n",
    "        team_name=current_team_name,\n",
    "        min_season=min_season,\n",
    "        max_season=max_season,\n",
    "        output_dir=raw_dir_transfermarkt,\n",
    "        output_filename=output_filename,\n",
    "        drop_metadata_columns=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Scraped data for {current_team_name}: {len(team_data)} records\")\n",
    "    print(f\"Saved to: {raw_dir_transfermarkt / output_filename}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf25ca1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137f73b",
   "metadata": {},
   "source": [
    "# Scrape multiple teams (FBRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ea10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 0) imports and constants\n",
    "# --------------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "import random, time, requests, pandas as pd, unicodedata, io\n",
    "\n",
    "TABLE_IDS = [\n",
    "    \"stats_standard_12\", \"stats_shooting_12\", \"stats_passing_12\",\n",
    "    \"stats_passing_types_12\", \"stats_gca_12\", \"stats_defense_12\",\n",
    "    \"stats_possession_12\",\n",
    "]\n",
    "SEASONS = [\"2223\", \"2324\", \"2425\"]\n",
    "\n",
    "TEAMS = {\n",
    "    # \"Real Madrid CF\":   \"53a2f082\", # We're getting 404s for this one, so we'll skip it for now\n",
    "    \"FC Barcelona\":     \"206d90db\",\n",
    "    \"Sevilla FC\":       \"ad2be733\",\n",
    "    # \"Atlético Madrid\":  \"db3b9613\",\n",
    "    \"Athletic Club\":    \"2b390eca\",\n",
    "    \"Villarreal CF\":    \"2a8183b3\",\n",
    "    \"Real Sociedad\":    \"e31d1cd9\",\n",
    "    \"Real Betis\":       \"fc536746\",\n",
    "    \"Valencia CF\":      \"dcc91a7b\",\n",
    "}\n",
    "\n",
    "def slugify(name: str) -> str:\n",
    "    \"\"\"Convert 'Atlético Madrid' → 'Atletico-Madrid-Stats'.\"\"\"\n",
    "    base = name.replace(\" CF\", \"\").replace(\" FC\", \"\")  # optional trims\n",
    "    base = unicodedata.normalize(\"NFD\", base)          # strip accents\n",
    "    base = \"\".join(c for c in base if unicodedata.category(c) != \"Mn\")\n",
    "    return base.replace(\" \", \"-\") + \"-Stats\"\n",
    "\n",
    "def polite_get(url: str) -> requests.Response:\n",
    "    hdr = {\"User-Agent\": \"Mozilla/5.0 (polite-bot/0.1)\"}\n",
    "    time.sleep(random.uniform(5, 10))\n",
    "    return requests.get(url, headers=hdr, timeout=40)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) main loop\n",
    "# --------------------------------------------------------------------\n",
    "for team, squad_id in TEAMS.items():\n",
    "    raw_dir = Path(\"..\", \"data\", \"raw\", team, \"fbref\")\n",
    "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    slug = slugify(team)\n",
    "\n",
    "    for season in SEASONS:\n",
    "\n",
    "        # build correct base URL\n",
    "        if season == \"2425\":\n",
    "            base_url = f\"https://fbref.com/en/squads/{squad_id}/{slug}\"\n",
    "        else:\n",
    "            base_url = (\n",
    "                f\"https://fbref.com/en/squads/{squad_id}/20{season[:2]}-20{season[2:]}/{slug}\"\n",
    "            )\n",
    "\n",
    "        # quick 404 check – skip if the page isn’t live yet\n",
    "        resp = polite_get(base_url)\n",
    "        if resp.status_code == 404:\n",
    "            print(f\"{team} {season}: page not found – skipped\")\n",
    "            continue\n",
    "\n",
    "        for t_id in TABLE_IDS:\n",
    "            name_part = t_id.replace(\"stats_\", \"\").replace(\"_12\", \"\")\n",
    "            csv_name  = (\n",
    "                f\"df_player_stats_{season}.csv\"\n",
    "                if t_id == \"stats_standard_12\"\n",
    "                else f\"df_player_{name_part}_{season}.csv\"\n",
    "            )\n",
    "            out_path = raw_dir / csv_name\n",
    "            if out_path.exists():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # pandas ≥3.0 wants StringIO, and we catch “no table” errors\n",
    "                df = pd.read_html(io.StringIO(resp.text), attrs={\"id\": t_id})[0]\n",
    "            except ValueError:\n",
    "                print(f\"{team} {season} {t_id}: table missing – skipped\")\n",
    "                continue\n",
    "\n",
    "            df.to_csv(out_path, index=False)\n",
    "            print(f\"{team} {season} {t_id} -> {out_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319bfa2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ce649",
   "metadata": {},
   "source": [
    "Since we're getting 404s for Real Madrid CF, we'll use Selenium to scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f36479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Dynamic Selenium Scraper that Detects Correct Table IDs\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def setup_selenium_driver() -> webdriver.Chrome:\n",
    "    \"\"\"Initialize headless Chrome driver for web scraping.\"\"\"\n",
    "    chrome_options: Options = Options()\n",
    "    chrome_options.headless = True\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    return webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def wait_for_table_to_load(selenium_driver: webdriver.Chrome, table_id: str, timeout_seconds: int = 10) -> bool:\n",
    "    \"\"\"Wait for a specific table to be present in the DOM.\"\"\"\n",
    "    try:\n",
    "        WebDriverWait(selenium_driver, timeout_seconds).until(\n",
    "            EC.presence_of_element_located((By.ID, table_id))\n",
    "        )\n",
    "        return True\n",
    "    except Exception as error:\n",
    "        print(f\"Table {table_id} not found: {error}\")\n",
    "        return False\n",
    "\n",
    "def detect_table_ids_on_page(selenium_driver: webdriver.Chrome) -> list:\n",
    "    \"\"\"Dynamically detect which table IDs are available on the current page.\"\"\"\n",
    "    # Look for any elements with 'stats' in their ID\n",
    "    all_elements_with_stats: list = selenium_driver.find_elements(By.CSS_SELECTOR, \"[id*='stats']\")\n",
    "    \n",
    "    # Extract the actual table IDs (not the wrapper divs)\n",
    "    table_ids = []\n",
    "    for element in all_elements_with_stats:\n",
    "        element_id: str = element.get_attribute(\"id\")\n",
    "        # Look for main table IDs (not the wrapper divs, links, etc.)\n",
    "        if (element_id.startswith(\"stats_\") and \n",
    "            not element_id.endswith(\"_link\") and \n",
    "            not element_id.endswith(\"_sh\") and \n",
    "            not element_id.endswith(\"_per_match_toggle\") and\n",
    "            not element_id.startswith(\"div_\") and\n",
    "            not element_id.startswith(\"tfooter_\") and\n",
    "            not element_id.startswith(\"sticky_style_\") and\n",
    "            not element_id.startswith(\"all_\")):\n",
    "            table_ids.append(element_id)\n",
    "    \n",
    "    return sorted(list(set(table_ids)))  # Remove duplicates and sort\n",
    "\n",
    "def debug_page_content(selenium_driver: webdriver.Chrome, table_id: str) -> None:\n",
    "    \"\"\"Debug function to check what tables are actually present on the page.\"\"\"\n",
    "    print(f\"\\nDebugging page content for table ID: {table_id}\")\n",
    "    \n",
    "    # Check current URL\n",
    "    current_url: str = selenium_driver.current_url\n",
    "    print(f\"Current URL: {current_url}\")\n",
    "    \n",
    "    # Check page title\n",
    "    page_title: str = selenium_driver.title\n",
    "    print(f\"Page title: {page_title}\")\n",
    "    \n",
    "    # Detect available table IDs\n",
    "    available_table_ids = detect_table_ids_on_page(selenium_driver)\n",
    "    print(f\"Available table IDs on page: {available_table_ids}\")\n",
    "    \n",
    "    # Check if the specific table ID exists\n",
    "    specific_table: list = selenium_driver.find_elements(By.ID, table_id)\n",
    "    if specific_table:\n",
    "        print(f\"Table {table_id} found in DOM\")\n",
    "    else:\n",
    "        print(f\"Table {table_id} NOT found in DOM\")\n",
    "\n",
    "def scrape_team_tables_with_selenium_dynamic(team_name: str, squad_id: str, season: str) -> None:\n",
    "    \"\"\"Scrape all statistical tables for a specific team and season using Selenium with dynamic table ID detection.\"\"\"\n",
    "    selenium_driver: webdriver.Chrome = setup_selenium_driver()\n",
    "    team_slug: str = slugify(team_name)\n",
    "    \n",
    "    # Build correct base URL for the season\n",
    "    if season == \"2425\":\n",
    "        base_url: str = f\"https://fbref.com/en/squads/{squad_id}/2024-2025/{team_slug}\"\n",
    "    else:\n",
    "        base_url: str = (\n",
    "            f\"https://fbref.com/en/squads/{squad_id}/20{season[:2]}-20{season[2:]}/{team_slug}\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Navigating to: {base_url}\")\n",
    "    \n",
    "    # Navigate to page and wait for initial load\n",
    "    selenium_driver.get(base_url)\n",
    "    time.sleep(5)  # Increased initial page load wait\n",
    "    \n",
    "    # Create output directory\n",
    "    raw_directory: Path = Path(\"..\", \"data\", \"raw\", team_name, \"fbref\")\n",
    "    raw_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Dynamically detect available table IDs on the page\n",
    "    available_table_ids = detect_table_ids_on_page(selenium_driver)\n",
    "    print(f\"Detected {len(available_table_ids)} available tables: {available_table_ids}\")\n",
    "    \n",
    "    # Define the table types we want to scrape\n",
    "    desired_table_types = [\n",
    "        \"stats_standard\", \"stats_shooting\", \"stats_passing\",\n",
    "        \"stats_passing_types\", \"stats_gca\", \"stats_defense\",\n",
    "        \"stats_possession\"\n",
    "    ]\n",
    "    \n",
    "    # Find matching table IDs for each desired type\n",
    "    table_ids_to_scrape = []\n",
    "    for desired_type in desired_table_types:\n",
    "        matching_ids = [tid for tid in available_table_ids if tid.startswith(desired_type)]\n",
    "        if matching_ids:\n",
    "            table_ids_to_scrape.append(matching_ids[0])  # Take the first match\n",
    "            print(f\"Found {desired_type}: {matching_ids[0]}\")\n",
    "        else:\n",
    "            print(f\"Missing {desired_type}\")\n",
    "    \n",
    "    # Scrape each detected table\n",
    "    for table_id in table_ids_to_scrape:\n",
    "        # Extract the base name for filename generation\n",
    "        table_name_part: str = table_id.replace(\"stats_\", \"\")\n",
    "        # Remove the suffix (could be _12, _719, etc.)\n",
    "        if \"_\" in table_name_part:\n",
    "            table_name_part = table_name_part.rsplit(\"_\", 1)[0]\n",
    "            \n",
    "        csv_filename: str = (\n",
    "            f\"df_player_stats_{season}.csv\"\n",
    "            if \"standard\" in table_id\n",
    "            else f\"df_player_{table_name_part}_{season}.csv\"\n",
    "        )\n",
    "            \n",
    "        output_path: Path = raw_directory / csv_filename\n",
    "        \n",
    "        if output_path.exists():\n",
    "            print(f\"{team_name} {season} {table_id}: file already exists – skipped\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing table: {table_id}\")\n",
    "        \n",
    "        # Wait for specific table to load\n",
    "        table_loaded: bool = wait_for_table_to_load(selenium_driver, table_id)\n",
    "        if not table_loaded:\n",
    "            print(f\"{team_name} {season} {table_id}: table not found in DOM – skipped\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Get fresh page source after table loads\n",
    "            current_page_html: str = selenium_driver.page_source\n",
    "            table_dataframe: pd.DataFrame = pd.read_html(\n",
    "                io.StringIO(current_page_html), \n",
    "                attrs={\"id\": table_id}\n",
    "            )[0]\n",
    "            table_dataframe.to_csv(output_path, index=False)\n",
    "            print(f\"{team_name} {season} {table_id} -> {output_path.name}\")\n",
    "        except ValueError as error:\n",
    "            print(f\"{team_name} {season} {table_id}: table extraction failed – {error}\")\n",
    "            continue\n",
    "    \n",
    "    selenium_driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ac761b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://fbref.com/en/squads/53a2f082/2024-2025/Real-Madrid-Stats\n",
      "Detected 11 available tables: ['stats_defense_12', 'stats_gca_12', 'stats_keeper_12', 'stats_keeper_adv_12', 'stats_misc_12', 'stats_passing_12', 'stats_passing_types_12', 'stats_playing_time_12', 'stats_possession_12', 'stats_shooting_12', 'stats_standard_12']\n",
      "Found stats_standard: stats_standard_12\n",
      "Found stats_shooting: stats_shooting_12\n",
      "Found stats_passing: stats_passing_12\n",
      "Found stats_passing_types: stats_passing_types_12\n",
      "Found stats_gca: stats_gca_12\n",
      "Found stats_defense: stats_defense_12\n",
      "Found stats_possession: stats_possession_12\n",
      "Real Madrid CF 2425 stats_standard_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_shooting_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_passing_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_passing_types_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_gca_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_defense_12: file already exists – skipped\n",
      "Real Madrid CF 2425 stats_possession_12: file already exists – skipped\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed scraper for Real Madrid 2024-25 season\n",
    "real_madrid_squad_id: str = \"53a2f082\"\n",
    "scrape_team_tables_with_selenium_dynamic(\"Real Madrid CF\", real_madrid_squad_id, \"2425\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da6f5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://fbref.com/en/squads/db3b9613/2024-2025/Atletico-Madrid-Stats\n",
      "Detected 11 available tables: ['stats_defense_12', 'stats_gca_12', 'stats_keeper_12', 'stats_keeper_adv_12', 'stats_misc_12', 'stats_passing_12', 'stats_passing_types_12', 'stats_playing_time_12', 'stats_possession_12', 'stats_shooting_12', 'stats_standard_12']\n",
      "Found stats_standard: stats_standard_12\n",
      "Found stats_shooting: stats_shooting_12\n",
      "Found stats_passing: stats_passing_12\n",
      "Found stats_passing_types: stats_passing_types_12\n",
      "Found stats_gca: stats_gca_12\n",
      "Found stats_defense: stats_defense_12\n",
      "Found stats_possession: stats_possession_12\n",
      "Atlético Madrid 2425 stats_standard_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_shooting_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_passing_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_passing_types_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_gca_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_defense_12: file already exists – skipped\n",
      "Atlético Madrid 2425 stats_possession_12: file already exists – skipped\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed scraper for Atlético Madrid 2024-25 season ()\n",
    "atletico_madrid_squad_id: str = \"db3b9613\"\n",
    "scrape_team_tables_with_selenium_dynamic(\"Atlético Madrid\", atletico_madrid_squad_id, \"2425\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df163d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".football-talent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
